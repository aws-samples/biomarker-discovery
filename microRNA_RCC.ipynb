{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "da56b7dd",
   "metadata": {},
   "source": [
    "# microRNA renal cell carcinoma prediction\n",
    "Note: cleaned data from preprocessing script must be input here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "2b113116",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "scipy version:  1.5.4\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import boto3\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from cox_functions import categorize_expression_levels, cox_ph_pipeline, normalize_gene_expression\n",
    "from copy import deepcopy\n",
    "\n",
    "from numpy.random import seed\n",
    "seed(1)\n",
    "\n",
    "import scipy\n",
    "print('scipy version: ', scipy.__version__)\n",
    "\n",
    "# !pip install lifelines\n",
    "\n",
    "from lifelines.utils import concordance_index\n",
    "from lifelines import CoxPHFitter\n",
    "\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# from XGBoostPipeline import XGBoostPipeline\n",
    "\n",
    "from XGBoostPipelineLatest import XGBoostPipeline\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "db7f3c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    df = pd.read_csv('../data/KIRC_TCGA_microRNA_expression_and_clinical.csv')\n",
    "    df.drop(columns=['Unnamed: 0'], inplace=True)\n",
    "    # DO NOT SET THE INDEX.  \n",
    "    # You will run into an issue where every CoxPH model will return a \n",
    "    # concordance of 0.5 no matter what subset of features you use if you set the index.\n",
    "\n",
    "    # Dropping columns that are not the target or related to microRNA expression\n",
    "\n",
    "    label = \"AJCC_PATHOLOGIC_TUMOR_STAGE\"\n",
    "\n",
    "    cols_to_drop = [\n",
    "        'PATIENT_ID',\n",
    "        \"SEX_male_female\",\n",
    "        \"RACE\", \n",
    "        \"ETHNICITY\",\n",
    "        \"DFS_STATUS\",\n",
    "        \"DFS_MONTHS\",\n",
    "    ]\n",
    "\n",
    "    df.drop(columns=cols_to_drop, inplace=True)\n",
    "\n",
    "    # From dataset joining, the NaN values for tumor stage have been verified to be normal patients\n",
    "    df[label].fillna('normal',inplace=True)\n",
    "\n",
    "    # Map tumor stage categories to numeric categories\n",
    "    tumor_stage_map = {\n",
    "        \"normal\" : 0,\n",
    "        \"STAGE I\" : 1,\n",
    "        \"STAGE II\" : 1,\n",
    "        \"STAGE III\" : 2,\n",
    "        \"STAGE IV\" : 2\n",
    "    }\n",
    "\n",
    "    df[label] = df[label].map(tumor_stage_map)\n",
    "    \n",
    "    \n",
    "    train, test = train_test_split(df, test_size=0.3, random_state=42, stratify=df[\"AJCC_PATHOLOGIC_TUMOR_STAGE\"].values)\n",
    "\n",
    "    train, val = train_test_split(train, test_size=0.2, random_state=32, stratify=train[\"AJCC_PATHOLOGIC_TUMOR_STAGE\"].values)\n",
    "    \n",
    "    dfph = deepcopy(train)\n",
    "    dfphtest = deepcopy(test)\n",
    "    dfphval = deepcopy(val)\n",
    "    \n",
    "    dfph.loc[dfph['AJCC_PATHOLOGIC_TUMOR_STAGE']==0,\"OS_STATUS\"]=\"0:LIVING\"\n",
    "    dfph.loc[dfph['AJCC_PATHOLOGIC_TUMOR_STAGE']==0,\"OS_MONTHS\"] = dfph['OS_MONTHS'].median()\n",
    "    \n",
    "    dfphval.loc[dfphval['AJCC_PATHOLOGIC_TUMOR_STAGE']==0,\"OS_STATUS\"]=\"0:LIVING\"\n",
    "    dfphval.loc[dfphval['AJCC_PATHOLOGIC_TUMOR_STAGE']==0,\"OS_MONTHS\"] = dfph['OS_MONTHS'].median()\n",
    "\n",
    "    dfphtest.loc[dfphtest['AJCC_PATHOLOGIC_TUMOR_STAGE']==0,\"OS_STATUS\"]=\"0:LIVING\"\n",
    "    dfphtest.loc[dfphtest['AJCC_PATHOLOGIC_TUMOR_STAGE']==0,\"OS_MONTHS\"] = dfph['OS_MONTHS'].median()\n",
    "\n",
    "    dfph['OS_STATUS'] = dfph['OS_STATUS'].astype('category').cat.codes\n",
    "    dfphval['OS_STATUS'] = dfphval['OS_STATUS'].astype('category').cat.codes\n",
    "    dfphtest['OS_STATUS'] = dfphtest['OS_STATUS'].astype('category').cat.codes\n",
    "    \n",
    "            \n",
    "    dfph.drop(columns=['hsa-mir-4296'], inplace=True)\n",
    "    dfphval.drop(columns=['hsa-mir-4296'], inplace=True)\n",
    "    dfphtest.drop(columns=['hsa-mir-4296'], inplace=True)\n",
    "    \n",
    "    empty_features = []\n",
    "    for col in dfph.columns:\n",
    "        if (dfph[col].sum() == 0):\n",
    "            empty_features.append(col)\n",
    "    \n",
    "    dfph.drop(columns=empty_features,inplace=True)\n",
    "    dfphval.drop(columns=empty_features,inplace=True)\n",
    "    dfphtest.drop(columns=empty_features,inplace=True)\n",
    "\n",
    "    gc = list(dfph.columns)\n",
    "    genes = gc[3:]\n",
    "\n",
    "#     return train, val, test, gc\n",
    "    return dfph, dfphval, dfphtest, genes, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "82134c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def normalize_expression(dfph, dfphval, dfphtest, genes):\n",
    "    \n",
    "#     dfph = normalize_gene_expression(dfph, genes);   \n",
    "#     dfphval = normalize_gene_expression(dfphval, genes);\n",
    "#     dfphtest = normalize_gene_expression(dfphtest, genes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "92c54934",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_cox(dfph, dfphval, dfphtest, genes, pvalue=.05):\n",
    "    \n",
    "    dfph = normalize_gene_expression(dfph, genes);   \n",
    "    dfphval = normalize_gene_expression(dfphval, genes);\n",
    "    dfphtest = normalize_gene_expression(dfphtest, genes)\n",
    "    \n",
    "    dfph = categorize_expression_levels(dfph, genes)\n",
    "    dfphval = categorize_expression_levels(dfphval, genes)    \n",
    "    dfphtest = categorize_expression_levels(dfphtest, genes)\n",
    "    \n",
    "    print('Running Cox PH on train set\\n')\n",
    "    info_map, significant_genes = cox_ph_pipeline(\n",
    "                dfph, \n",
    "                genes, \n",
    "                dataset_name=\"final_microRNA_plus_normal_trainvaltest\", \n",
    "                duration=\"OS_MONTHS\", \n",
    "                event=\"OS_STATUS\",\n",
    "                pvalue=pvalue\n",
    "    )\n",
    "    print('number of significant genes: ',len(significant_genes))\n",
    "    return dfph, dfphval, dfphtest, info_map, significant_genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "930f6077",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_format_xgbpipeline(significant_genes, label = \"AJCC_PATHOLOGIC_TUMOR_STAGE\"):\n",
    "    input_df = deepcopy(dfph[[label] + significant_genes])\n",
    "    input_df_val = deepcopy(dfphval[[label] + significant_genes])\n",
    "    input_df_test = deepcopy(dfphtest[[label] + significant_genes])\n",
    "\n",
    "    all_columns = input_df.columns # Creates list of all column headers\n",
    "    input_df[all_columns[1:]] = input_df[all_columns[1:]].astype('float')\n",
    "    input_df_val[all_columns[1:]] = input_df_val[all_columns[1:]].astype('float')\n",
    "    input_df_test[all_columns[1:]] = input_df_test[all_columns[1:]].astype('float')\n",
    "    \n",
    "    return input_df, input_df_val, input_df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "65e57d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_xgbpipeline(input_df_test, pipeline):\n",
    "    xgb_model = XGBClassifier()\n",
    "    xgb_model.load_model(pipeline.model_filepath)\n",
    "    hr_pred = xgb_model.predict(input_df_test[input_df_test.columns[1:]])\n",
    "    hr_pred_proba = xgb_model.predict_proba(input_df_test[input_df_test.columns[1:]])#,validate_features=True)#, input_df_test[input_df.columns[0]].values-1)\n",
    "    hr_pred_proba_norm = hr_pred_proba[:,np.shape(hr_pred_proba)[1]//2:].T\n",
    "    roc_auc_score_ovo = roc_auc_score(\n",
    "                input_df_test[input_df_test.columns[0]].values,\n",
    "                hr_pred_proba_norm,\n",
    "                multi_class='ovo'\n",
    "            )\n",
    "\n",
    "    roc_auc_score_ovr = roc_auc_score(\n",
    "                input_df_test[input_df_test.columns[0]].values,\n",
    "                hr_pred_proba_norm,\n",
    "                multi_class='ovr'\n",
    "            )\n",
    "    print(classification_report(hr_pred, input_df_test[input_df_test.columns[0]]))\n",
    "    print('roc_auc_ovo: ', roc_auc_score_ovo, 'roc_auc_ovr: ',roc_auc_score_ovr)\n",
    "    return roc_auc_score_ovo, roc_auc_score_ovr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "f1ce97fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log-transforming gene expression data\n",
      "Normalizing gene expression\n",
      "Log-transforming gene expression data\n",
      "Normalizing gene expression\n",
      "Log-transforming gene expression data\n",
      "Normalizing gene expression\n",
      "Running Cox PH on train set\n",
      "\n",
      "Saving Cox PH JSON results to: ../final_results/final_microRNA_plus_normal_trainvaltest_individual_cox_results.json\n",
      "number of significant genes:  47\n"
     ]
    }
   ],
   "source": [
    "dfph, dfphval, dfphtest, genes, label = load_data()\n",
    "\n",
    "dfph, dfphval, dfphtest, info_map, significant_genes = run_cox(dfph, dfphval, dfphtest, genes, pvalue = 0.05)\n",
    "\n",
    "input_df, input_df_val, input_df_test = data_format_xgbpipeline(significant_genes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "cbff35ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing pipeline:\n"
     ]
    }
   ],
   "source": [
    "pipeline = XGBoostPipeline(    \n",
    "    pd.concat([input_df,input_df_val]),\n",
    "    random_state=60, \n",
    "    label_column=label,\n",
    "    num_classes=3, \n",
    "    weighted=False,\n",
    "    n_iter=40,\n",
    "    model_name=\"final_microRNA_multiclass_post_cox_bayes_opt_xgboost_best_james_ttv_latest.json\",\n",
    "    json_filepath=\"final_microRNA_multiclass_post_cox_bayes_opt_xgboost_best_output_james_ttv_latest.json\",\n",
    "    dataset_name=\"final_microRNA\",\n",
    "#     X_train=input_df[input_df.columns[1:]],\n",
    "#     y_train=input_df[input_df.columns[0]],\n",
    "#     X_test=input_df_val[input_df.columns[1:]],\n",
    "#     y_test=input_df_val[input_df.columns[0]]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "c21a7b29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing test and train data:\n",
      "Running XGBoost pipeline\n",
      "Beginning Bayesian Optimization:\n",
      "\n",
      "|   iter    |  target   |    eta    |   gamma   | max_de... | max_depth |\n",
      "-------------------------------------------------------------------------\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m 0.8544  \u001b[0m | \u001b[0m 0.3079  \u001b[0m | \u001b[0m 0.1869  \u001b[0m | \u001b[0m 8.756   \u001b[0m | \u001b[0m 7.66    \u001b[0m |\n",
      "| \u001b[95m 2       \u001b[0m | \u001b[95m 0.8696  \u001b[0m | \u001b[95m 0.5713  \u001b[0m | \u001b[95m 0.3983  \u001b[0m | \u001b[95m 10.11   \u001b[0m | \u001b[95m 3.074   \u001b[0m |\n",
      "| \u001b[0m 3       \u001b[0m | \u001b[0m 0.8578  \u001b[0m | \u001b[0m 0.1787  \u001b[0m | \u001b[0m 0.1234  \u001b[0m | \u001b[0m 17.62   \u001b[0m | \u001b[0m 9.121   \u001b[0m |\n",
      "| \u001b[0m 4       \u001b[0m | \u001b[0m 0.8498  \u001b[0m | \u001b[0m 0.6531  \u001b[0m | \u001b[0m 0.5155  \u001b[0m | \u001b[0m 17.99   \u001b[0m | \u001b[0m 9.489   \u001b[0m |\n",
      "| \u001b[0m 5       \u001b[0m | \u001b[0m 0.8653  \u001b[0m | \u001b[0m 0.3702  \u001b[0m | \u001b[0m 0.4326  \u001b[0m | \u001b[0m 9.973   \u001b[0m | \u001b[0m 3.082   \u001b[0m |\n",
      "| \u001b[0m 6       \u001b[0m | \u001b[0m 0.8306  \u001b[0m | \u001b[0m 0.8212  \u001b[0m | \u001b[0m 0.3174  \u001b[0m | \u001b[0m 10.06   \u001b[0m | \u001b[0m 3.393   \u001b[0m |\n",
      "| \u001b[0m 7       \u001b[0m | \u001b[0m 0.8512  \u001b[0m | \u001b[0m 0.2105  \u001b[0m | \u001b[0m 0.002204\u001b[0m | \u001b[0m 17.54   \u001b[0m | \u001b[0m 9.122   \u001b[0m |\n",
      "| \u001b[0m 8       \u001b[0m | \u001b[0m 0.8541  \u001b[0m | \u001b[0m 0.2987  \u001b[0m | \u001b[0m 0.4399  \u001b[0m | \u001b[0m 20.32   \u001b[0m | \u001b[0m 4.93    \u001b[0m |\n",
      "| \u001b[0m 9       \u001b[0m | \u001b[0m 0.8571  \u001b[0m | \u001b[0m 0.4406  \u001b[0m | \u001b[0m 0.5044  \u001b[0m | \u001b[0m 10.16   \u001b[0m | \u001b[0m 3.23    \u001b[0m |\n",
      "| \u001b[0m 10      \u001b[0m | \u001b[0m 0.8446  \u001b[0m | \u001b[0m 0.2404  \u001b[0m | \u001b[0m 0.507   \u001b[0m | \u001b[0m 19.63   \u001b[0m | \u001b[0m 4.861   \u001b[0m |\n",
      "| \u001b[0m 11      \u001b[0m | \u001b[0m 0.854   \u001b[0m | \u001b[0m 0.2899  \u001b[0m | \u001b[0m 0.317   \u001b[0m | \u001b[0m 10.01   \u001b[0m | \u001b[0m 3.156   \u001b[0m |\n",
      "| \u001b[0m 12      \u001b[0m | \u001b[0m 0.8447  \u001b[0m | \u001b[0m 0.5931  \u001b[0m | \u001b[0m 0.7266  \u001b[0m | \u001b[0m 6.536   \u001b[0m | \u001b[0m 7.18    \u001b[0m |\n",
      "| \u001b[0m 13      \u001b[0m | \u001b[0m 0.8509  \u001b[0m | \u001b[0m 0.6104  \u001b[0m | \u001b[0m 0.9627  \u001b[0m | \u001b[0m 18.81   \u001b[0m | \u001b[0m 6.315   \u001b[0m |\n",
      "| \u001b[0m 14      \u001b[0m | \u001b[0m 0.8627  \u001b[0m | \u001b[0m 0.3733  \u001b[0m | \u001b[0m 0.4848  \u001b[0m | \u001b[0m 10.25   \u001b[0m | \u001b[0m 3.019   \u001b[0m |\n",
      "| \u001b[0m 15      \u001b[0m | \u001b[0m 0.844   \u001b[0m | \u001b[0m 0.4881  \u001b[0m | \u001b[0m 0.4348  \u001b[0m | \u001b[0m 9.022   \u001b[0m | \u001b[0m 7.064   \u001b[0m |\n",
      "| \u001b[0m 16      \u001b[0m | \u001b[0m 0.8619  \u001b[0m | \u001b[0m 0.6778  \u001b[0m | \u001b[0m 0.4093  \u001b[0m | \u001b[0m 21.09   \u001b[0m | \u001b[0m 8.946   \u001b[0m |\n",
      "| \u001b[0m 17      \u001b[0m | \u001b[0m 0.8395  \u001b[0m | \u001b[0m 0.411   \u001b[0m | \u001b[0m 0.7862  \u001b[0m | \u001b[0m 14.58   \u001b[0m | \u001b[0m 7.948   \u001b[0m |\n",
      "| \u001b[0m 18      \u001b[0m | \u001b[0m 0.8506  \u001b[0m | \u001b[0m 0.1092  \u001b[0m | \u001b[0m 0.6398  \u001b[0m | \u001b[0m 4.482   \u001b[0m | \u001b[0m 7.056   \u001b[0m |\n",
      "| \u001b[0m 19      \u001b[0m | \u001b[0m 0.849   \u001b[0m | \u001b[0m 0.3915  \u001b[0m | \u001b[0m 0.4387  \u001b[0m | \u001b[0m 12.75   \u001b[0m | \u001b[0m 3.657   \u001b[0m |\n",
      "| \u001b[0m 20      \u001b[0m | \u001b[0m 0.8523  \u001b[0m | \u001b[0m 0.3586  \u001b[0m | \u001b[0m 0.4525  \u001b[0m | \u001b[0m 20.24   \u001b[0m | \u001b[0m 4.946   \u001b[0m |\n",
      "| \u001b[0m 21      \u001b[0m | \u001b[0m 0.851   \u001b[0m | \u001b[0m 0.4761  \u001b[0m | \u001b[0m 0.2154  \u001b[0m | \u001b[0m 10.11   \u001b[0m | \u001b[0m 3.069   \u001b[0m |\n",
      "| \u001b[0m 22      \u001b[0m | \u001b[0m 0.8412  \u001b[0m | \u001b[0m 0.4418  \u001b[0m | \u001b[0m 0.02744 \u001b[0m | \u001b[0m 5.208   \u001b[0m | \u001b[0m 3.816   \u001b[0m |\n",
      "| \u001b[0m 23      \u001b[0m | \u001b[0m 0.8479  \u001b[0m | \u001b[0m 0.1296  \u001b[0m | \u001b[0m 0.7031  \u001b[0m | \u001b[0m 3.519   \u001b[0m | \u001b[0m 4.924   \u001b[0m |\n",
      "| \u001b[0m 24      \u001b[0m | \u001b[0m 0.8644  \u001b[0m | \u001b[0m 0.4907  \u001b[0m | \u001b[0m 0.3646  \u001b[0m | \u001b[0m 9.79    \u001b[0m | \u001b[0m 3.122   \u001b[0m |\n",
      "| \u001b[0m 25      \u001b[0m | \u001b[0m 0.8525  \u001b[0m | \u001b[0m 0.1834  \u001b[0m | \u001b[0m 0.3385  \u001b[0m | \u001b[0m 13.34   \u001b[0m | \u001b[0m 4.071   \u001b[0m |\n",
      "| \u001b[0m 26      \u001b[0m | \u001b[0m 0.8479  \u001b[0m | \u001b[0m 0.3806  \u001b[0m | \u001b[0m 0.1464  \u001b[0m | \u001b[0m 8.71    \u001b[0m | \u001b[0m 7.672   \u001b[0m |\n",
      "| \u001b[0m 27      \u001b[0m | \u001b[0m 0.857   \u001b[0m | \u001b[0m 0.5472  \u001b[0m | \u001b[0m 0.7215  \u001b[0m | \u001b[0m 10.12   \u001b[0m | \u001b[0m 3.079   \u001b[0m |\n",
      "| \u001b[0m 28      \u001b[0m | \u001b[0m 0.8466  \u001b[0m | \u001b[0m 0.5029  \u001b[0m | \u001b[0m 0.03311 \u001b[0m | \u001b[0m 6.984   \u001b[0m | \u001b[0m 3.983   \u001b[0m |\n",
      "| \u001b[0m 29      \u001b[0m | \u001b[0m 0.8532  \u001b[0m | \u001b[0m 0.8002  \u001b[0m | \u001b[0m 0.3926  \u001b[0m | \u001b[0m 21.01   \u001b[0m | \u001b[0m 9.065   \u001b[0m |\n",
      "| \u001b[0m 30      \u001b[0m | \u001b[0m 0.8432  \u001b[0m | \u001b[0m 0.9915  \u001b[0m | \u001b[0m 0.9303  \u001b[0m | \u001b[0m 12.44   \u001b[0m | \u001b[0m 6.683   \u001b[0m |\n",
      "| \u001b[0m 31      \u001b[0m | \u001b[0m 0.862   \u001b[0m | \u001b[0m 0.698   \u001b[0m | \u001b[0m 0.3968  \u001b[0m | \u001b[0m 21.27   \u001b[0m | \u001b[0m 8.887   \u001b[0m |\n",
      "| \u001b[0m 32      \u001b[0m | \u001b[0m 0.8459  \u001b[0m | \u001b[0m 0.3361  \u001b[0m | \u001b[0m 0.007821\u001b[0m | \u001b[0m 6.018   \u001b[0m | \u001b[0m 9.401   \u001b[0m |\n",
      "| \u001b[0m 33      \u001b[0m | \u001b[0m 0.8614  \u001b[0m | \u001b[0m 0.2557  \u001b[0m | \u001b[0m 0.4542  \u001b[0m | \u001b[0m 9.655   \u001b[0m | \u001b[0m 3.128   \u001b[0m |\n",
      "| \u001b[0m 34      \u001b[0m | \u001b[0m 0.8619  \u001b[0m | \u001b[0m 0.858   \u001b[0m | \u001b[0m 0.4935  \u001b[0m | \u001b[0m 5.466   \u001b[0m | \u001b[0m 4.311   \u001b[0m |\n",
      "| \u001b[0m 35      \u001b[0m | \u001b[0m 0.8422  \u001b[0m | \u001b[0m 0.3651  \u001b[0m | \u001b[0m 0.03267 \u001b[0m | \u001b[0m 19.47   \u001b[0m | \u001b[0m 3.558   \u001b[0m |\n",
      "| \u001b[0m 36      \u001b[0m | \u001b[0m 0.8612  \u001b[0m | \u001b[0m 0.5585  \u001b[0m | \u001b[0m 0.3441  \u001b[0m | \u001b[0m 10.01   \u001b[0m | \u001b[0m 3.106   \u001b[0m |\n",
      "| \u001b[0m 37      \u001b[0m | \u001b[0m 0.8577  \u001b[0m | \u001b[0m 0.4714  \u001b[0m | \u001b[0m 0.3787  \u001b[0m | \u001b[0m 21.21   \u001b[0m | \u001b[0m 8.999   \u001b[0m |\n",
      "| \u001b[0m 38      \u001b[0m | \u001b[0m 0.8528  \u001b[0m | \u001b[0m 0.4676  \u001b[0m | \u001b[0m 0.4829  \u001b[0m | \u001b[0m 10.2    \u001b[0m | \u001b[0m 3.017   \u001b[0m |\n",
      "| \u001b[0m 39      \u001b[0m | \u001b[0m 0.8658  \u001b[0m | \u001b[0m 0.297   \u001b[0m | \u001b[0m 0.437   \u001b[0m | \u001b[0m 9.666   \u001b[0m | \u001b[0m 3.279   \u001b[0m |\n",
      "| \u001b[0m 40      \u001b[0m | \u001b[0m 0.8572  \u001b[0m | \u001b[0m 0.2947  \u001b[0m | \u001b[0m 0.392   \u001b[0m | \u001b[0m 10.04   \u001b[0m | \u001b[0m 3.192   \u001b[0m |\n",
      "| \u001b[0m 41      \u001b[0m | \u001b[0m 0.8481  \u001b[0m | \u001b[0m 0.4299  \u001b[0m | \u001b[0m 0.5872  \u001b[0m | \u001b[0m 24.71   \u001b[0m | \u001b[0m 5.879   \u001b[0m |\n",
      "| \u001b[0m 42      \u001b[0m | \u001b[0m 0.8475  \u001b[0m | \u001b[0m 0.2918  \u001b[0m | \u001b[0m 0.8823  \u001b[0m | \u001b[0m 4.802   \u001b[0m | \u001b[0m 9.482   \u001b[0m |\n",
      "| \u001b[0m 43      \u001b[0m | \u001b[0m 0.8576  \u001b[0m | \u001b[0m 0.6038  \u001b[0m | \u001b[0m 0.4067  \u001b[0m | \u001b[0m 13.59   \u001b[0m | \u001b[0m 4.432   \u001b[0m |\n",
      "=========================================================================\n",
      "Best AUC: 0.8696064814814815\n",
      "Best parameters: {'eta': 0.5713010929595213, 'gamma': 0.3982539588987647, 'max_delta_step': 10.105957972590318, 'max_depth': 3.0740707511505008}\n",
      "{'eta': 0.5713010929595213, 'gamma': 0.3982539588987647, 'max_delta_step': 10.105957972590318, 'max_depth': 3, 'eval_metric': 'auc', 'objective': 'multi:softprob', 'num_class': 3, 'min_child_weight': 1, 'subsample': 1, 'colsample_bytree': 1}\n",
      "Training XGBoost model\n",
      "[0]\tTest-auc:0.85054\n",
      "[1]\tTest-auc:0.82771\n",
      "[2]\tTest-auc:0.82539\n",
      "[3]\tTest-auc:0.82019\n",
      "[4]\tTest-auc:0.82268\n",
      "[5]\tTest-auc:0.83033\n",
      "[6]\tTest-auc:0.82762\n",
      "[7]\tTest-auc:0.82073\n",
      "[8]\tTest-auc:0.82194\n",
      "[9]\tTest-auc:0.82392\n",
      "[10]\tTest-auc:0.82242\n",
      "[11]\tTest-auc:0.81901\n",
      "[12]\tTest-auc:0.82147\n",
      "[13]\tTest-auc:0.81458\n",
      "[14]\tTest-auc:0.82022\n",
      "[15]\tTest-auc:0.81923\n",
      "[16]\tTest-auc:0.81923\n",
      "[17]\tTest-auc:0.82169\n",
      "[18]\tTest-auc:0.82908\n",
      "[19]\tTest-auc:0.82908\n",
      "[20]\tTest-auc:0.82908\n",
      "[21]\tTest-auc:0.82810\n",
      "[22]\tTest-auc:0.82810\n",
      "[23]\tTest-auc:0.82810\n",
      "[24]\tTest-auc:0.82810\n",
      "[25]\tTest-auc:0.82810\n",
      "[26]\tTest-auc:0.82810\n",
      "[27]\tTest-auc:0.82810\n",
      "[28]\tTest-auc:0.82810\n",
      "[29]\tTest-auc:0.82810\n",
      "[30]\tTest-auc:0.82810\n",
      "[31]\tTest-auc:0.82810\n",
      "[32]\tTest-auc:0.82810\n",
      "[33]\tTest-auc:0.82810\n",
      "[34]\tTest-auc:0.82810\n",
      "[35]\tTest-auc:0.82810\n",
      "[36]\tTest-auc:0.82810\n",
      "[37]\tTest-auc:0.82810\n",
      "[38]\tTest-auc:0.82810\n",
      "[39]\tTest-auc:0.82810\n",
      "[40]\tTest-auc:0.82810\n",
      "[41]\tTest-auc:0.82810\n",
      "[42]\tTest-auc:0.82810\n",
      "[43]\tTest-auc:0.82810\n",
      "[44]\tTest-auc:0.82810\n",
      "[45]\tTest-auc:0.82810\n",
      "[46]\tTest-auc:0.82810\n",
      "[47]\tTest-auc:0.82810\n",
      "[48]\tTest-auc:0.82810\n",
      "[49]\tTest-auc:0.82810\n",
      "[50]\tTest-auc:0.82810\n",
      "[51]\tTest-auc:0.82810\n",
      "[52]\tTest-auc:0.82810\n",
      "[53]\tTest-auc:0.82810\n",
      "[54]\tTest-auc:0.82810\n",
      "[55]\tTest-auc:0.82810\n",
      "[56]\tTest-auc:0.82810\n",
      "[57]\tTest-auc:0.82810\n",
      "[58]\tTest-auc:0.82810\n",
      "[59]\tTest-auc:0.82810\n",
      "[60]\tTest-auc:0.82810\n",
      "[61]\tTest-auc:0.82810\n",
      "[62]\tTest-auc:0.82810\n",
      "[63]\tTest-auc:0.82810\n",
      "[64]\tTest-auc:0.82810\n",
      "[65]\tTest-auc:0.82810\n",
      "[66]\tTest-auc:0.82810\n",
      "[67]\tTest-auc:0.82810\n",
      "[68]\tTest-auc:0.82810\n",
      "[69]\tTest-auc:0.82810\n",
      "[70]\tTest-auc:0.82810\n",
      "[71]\tTest-auc:0.82810\n",
      "[72]\tTest-auc:0.82810\n",
      "[73]\tTest-auc:0.82810\n",
      "[74]\tTest-auc:0.82810\n",
      "[75]\tTest-auc:0.82810\n",
      "[76]\tTest-auc:0.82810\n",
      "[77]\tTest-auc:0.82810\n",
      "[78]\tTest-auc:0.82810\n",
      "[79]\tTest-auc:0.82810\n",
      "[80]\tTest-auc:0.82810\n",
      "[81]\tTest-auc:0.82810\n",
      "[82]\tTest-auc:0.82810\n",
      "[83]\tTest-auc:0.82810\n",
      "[84]\tTest-auc:0.82810\n",
      "[85]\tTest-auc:0.82810\n",
      "[86]\tTest-auc:0.82810\n",
      "[87]\tTest-auc:0.82810\n",
      "[88]\tTest-auc:0.82810\n",
      "[89]\tTest-auc:0.82810\n",
      "[90]\tTest-auc:0.82810\n",
      "[91]\tTest-auc:0.82810\n",
      "[92]\tTest-auc:0.82810\n",
      "[93]\tTest-auc:0.82810\n",
      "[94]\tTest-auc:0.82810\n",
      "[95]\tTest-auc:0.82810\n",
      "[96]\tTest-auc:0.82810\n",
      "[97]\tTest-auc:0.82810\n",
      "[98]\tTest-auc:0.82810\n",
      "[99]\tTest-auc:0.82810\n",
      "[100]\tTest-auc:0.82810\n",
      "Saving model to:  ../final_results/XGBoost/final_microRNA_multiclass_post_cox_bayes_opt_xgboost_best_james_ttv_latest.json\n",
      "Saving XGBoost JSON results to: ../final_results/XGBoost/final_microRNA_multiclass_post_cox_bayes_opt_xgboost_best_output_james_ttv_latest.json\n",
      "Creating importance matrix\n",
      "Saving importance matrix to: ../final_results/XGBoost/final_microRNA_xgboost_feature_importance.csv\n",
      "Results summary:\n",
      "Parameter bounds: {'max_depth': (3, 10), 'eta': (0.01, 1), 'gamma': (0.0, 1), 'max_delta_step': (1, 25)}\n",
      "Number of boosting rounds: 1000\n",
      "Early stopping rounds: 100\n",
      "Accuracy = 0.7045454545454546\n",
      "ROC AUC OVO = 0.8764346764346764\n",
      "ROC AUC OVR = 0.8493750288981706\n",
      "Model filepath = ../final_results/XGBoost/final_microRNA_multiclass_post_cox_bayes_opt_xgboost_best_james_ttv_latest.json\n",
      "Importance matrix filepath = ../final_results/XGBoost/final_microRNA_xgboost_feature_importance.csv\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.80      0.87        25\n",
      "           1       0.64      0.66      0.65        44\n",
      "           2       0.43      0.48      0.45        25\n",
      "\n",
      "    accuracy                           0.65        94\n",
      "   macro avg       0.68      0.65      0.66        94\n",
      "weighted avg       0.67      0.65      0.66        94\n",
      "\n",
      "roc_auc_ovo:  0.8418052406147645 roc_auc_ovr:  0.8136595194325137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/xgboost/sklearn.py:567: UserWarning: Loading a native XGBoost model with Scikit-Learn interface.\n",
      "  'Loading a native XGBoost model with Scikit-Learn interface.')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.8418052406147645, 0.8136595194325137)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.run_workflow()\n",
    "\n",
    "# pipeline.print_summary()\n",
    "\n",
    "evaluate_xgbpipeline(input_df_test, pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "0a498127",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def save_importance_matrix(model, dataset_name='final_microRNA_james'):\n",
    "\n",
    "    print(\"Creating importance matrix\")\n",
    "\n",
    "    feature_importance_dict = {}\n",
    "    importance_types = ['gain', 'cover', 'weight', 'total_gain', 'total_cover']\n",
    "\n",
    "    for metric in importance_types:\n",
    "        feature_importance_dict[metric] = model.get_booster().get_score(importance_type=metric)\n",
    "\n",
    "    importance_matrix = pd.DataFrame(feature_importance_dict)\n",
    "    importance_matrix_filepath = \"../final_results/XGBoost/{}_xgboost_feature_importance_latest.csv\".format(dataset_name)\n",
    "\n",
    "#         print(\"Saving importance matrix to:\", importance_matrix_filepath)\n",
    "#         importance_matrix.to_csv(importance_matrix_filepath)\n",
    "\n",
    "    return importance_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "85c5239b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:59:23] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/xgboost/core.py:433: FutureWarning: Pass `objective` as keyword args.  Passing these as positional arguments will be considered as error in future releases.\n",
      "  format(\", \".join(args_msg)), FutureWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=100, n_jobs=16, num_parallel_tree=1,\n",
       "              objective='multi:softprob', random_state=0, reg_alpha=0,\n",
       "              reg_lambda=1, scale_pos_weight=None, subsample=1,\n",
       "              tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_df_final = pd.concat([input_df,input_df_val])\n",
    "\n",
    "xgb_model_final = XGBClassifier(pipeline.best_params,objective='multi:softprob')\n",
    "\n",
    "xgb_model_final.fit(X=input_df_final[input_df_final.columns[1:]],y=input_df_final[input_df_final.columns[0]])#,eval_metric='multi:softprob')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a0d839b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "from xgboost import plot_importance\n",
    "\n",
    "# Get the booster from the xgbmodel\n",
    "booster = xgb_model_final.get_booster()\n",
    "\n",
    "# Get the importance dictionary (by gain) from the booster\n",
    "importance = booster.get_score(importance_type=\"gain\")\n",
    "\n",
    "# make your changes\n",
    "for key in importance.keys():\n",
    "    importance[key] = round(importance[key],2)\n",
    "\n",
    "# provide the importance dictionary to the plotting function\n",
    "ax = plot_importance(importance, max_num_features=20, importance_type='gain', show_values=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cb01481",
   "metadata": {},
   "outputs": [],
   "source": [
    "hr_pred_proba = xgb_model_final.predict_proba(input_df_test[input_df.columns[1:]])#,validate_features=True)#, input_df_test[input_df.columns[0]].values-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "44665d8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(94, 3)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hr_pred_proba = xgb_model_final.predict_proba(input_df_test[input_df.columns[1:]])#,validate_features=True)#, input_df_test[input_df.columns[0]].values-1)\n",
    "\n",
    "\n",
    "hr_pred_proba.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "d436472d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(hr_pred_proba[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "23c85116",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "be999635",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.648936170212766"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(np.argmax(hr_pred_proba,axis=1), input_df_test[input_df.columns[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "2938c9cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      1.00      0.92        18\n",
      "           1       0.64      0.63      0.64        46\n",
      "           2       0.50      0.47      0.48        30\n",
      "\n",
      "    accuracy                           0.65        94\n",
      "   macro avg       0.67      0.70      0.68        94\n",
      "weighted avg       0.64      0.65      0.64        94\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(np.argmax(hr_pred_proba,axis=1), input_df_test[input_df.columns[0]]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "59f7abfb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8686696900982614"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print(classification_report(hr_pred_proba.T[188//2:,:], input_df_test[input_df.columns[0]]))\n",
    "\n",
    "roc_auc_score(\n",
    "            input_df_test[input_df.columns[0]].values,\n",
    "            hr_pred_proba[:,:],\n",
    "#             self.y_pred if len(np.shape(self.y_pred))==1 else self.y_pred[:,1], \n",
    "            multi_class='ovo'\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "74309cf5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8450807817246173"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(\n",
    "            input_df_test[input_df.columns[0]].values,\n",
    "            hr_pred_proba[:,:],\n",
    "#             self.y_pred if len(np.shape(self.y_pred))==1 else self.y_pred[:,1], \n",
    "            multi_class='ovr'\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "945b50d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating importance matrix\n"
     ]
    }
   ],
   "source": [
    "imp = save_importance_matrix(xgb_model_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bb98682b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gain</th>\n",
       "      <th>cover</th>\n",
       "      <th>weight</th>\n",
       "      <th>total_gain</th>\n",
       "      <th>total_cover</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>hsa-let-7i</th>\n",
       "      <td>1.040161</td>\n",
       "      <td>16.614639</td>\n",
       "      <td>59.0</td>\n",
       "      <td>61.369476</td>\n",
       "      <td>980.263733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hsa-mir-1-2</th>\n",
       "      <td>0.174002</td>\n",
       "      <td>5.095908</td>\n",
       "      <td>20.0</td>\n",
       "      <td>3.480048</td>\n",
       "      <td>101.918167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hsa-mir-10a</th>\n",
       "      <td>0.258901</td>\n",
       "      <td>5.837817</td>\n",
       "      <td>58.0</td>\n",
       "      <td>15.016255</td>\n",
       "      <td>338.593384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hsa-mir-10b</th>\n",
       "      <td>0.217785</td>\n",
       "      <td>5.103403</td>\n",
       "      <td>18.0</td>\n",
       "      <td>3.920134</td>\n",
       "      <td>91.861244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hsa-mir-1228</th>\n",
       "      <td>0.239293</td>\n",
       "      <td>5.473589</td>\n",
       "      <td>45.0</td>\n",
       "      <td>10.768188</td>\n",
       "      <td>246.311508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hsa-mir-125a</th>\n",
       "      <td>0.212783</td>\n",
       "      <td>5.898917</td>\n",
       "      <td>38.0</td>\n",
       "      <td>8.085759</td>\n",
       "      <td>224.158829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hsa-mir-125b-1</th>\n",
       "      <td>0.221412</td>\n",
       "      <td>5.084087</td>\n",
       "      <td>53.0</td>\n",
       "      <td>11.734852</td>\n",
       "      <td>269.456604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hsa-mir-1277</th>\n",
       "      <td>0.166627</td>\n",
       "      <td>4.382925</td>\n",
       "      <td>31.0</td>\n",
       "      <td>5.165445</td>\n",
       "      <td>135.870667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hsa-mir-129-1</th>\n",
       "      <td>0.833234</td>\n",
       "      <td>7.673101</td>\n",
       "      <td>64.0</td>\n",
       "      <td>53.326962</td>\n",
       "      <td>491.078491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hsa-mir-1307</th>\n",
       "      <td>0.140200</td>\n",
       "      <td>5.436034</td>\n",
       "      <td>58.0</td>\n",
       "      <td>8.131577</td>\n",
       "      <td>315.289978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hsa-mir-130b</th>\n",
       "      <td>0.286619</td>\n",
       "      <td>7.942135</td>\n",
       "      <td>33.0</td>\n",
       "      <td>9.458432</td>\n",
       "      <td>262.090454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hsa-mir-133a-1</th>\n",
       "      <td>0.222085</td>\n",
       "      <td>4.599783</td>\n",
       "      <td>53.0</td>\n",
       "      <td>11.770526</td>\n",
       "      <td>243.788498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hsa-mir-133a-2</th>\n",
       "      <td>0.275118</td>\n",
       "      <td>9.722225</td>\n",
       "      <td>58.0</td>\n",
       "      <td>15.956835</td>\n",
       "      <td>563.889038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hsa-mir-133b</th>\n",
       "      <td>0.061800</td>\n",
       "      <td>4.632619</td>\n",
       "      <td>39.0</td>\n",
       "      <td>2.410219</td>\n",
       "      <td>180.672134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hsa-mir-135a-2</th>\n",
       "      <td>0.122232</td>\n",
       "      <td>4.478873</td>\n",
       "      <td>57.0</td>\n",
       "      <td>6.967252</td>\n",
       "      <td>255.295761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hsa-mir-139</th>\n",
       "      <td>0.330916</td>\n",
       "      <td>6.503644</td>\n",
       "      <td>37.0</td>\n",
       "      <td>12.243883</td>\n",
       "      <td>240.634827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hsa-mir-142</th>\n",
       "      <td>0.197411</td>\n",
       "      <td>6.304322</td>\n",
       "      <td>30.0</td>\n",
       "      <td>5.922344</td>\n",
       "      <td>189.129669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hsa-mir-153-2</th>\n",
       "      <td>0.186509</td>\n",
       "      <td>4.583476</td>\n",
       "      <td>25.0</td>\n",
       "      <td>4.662715</td>\n",
       "      <td>114.586906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hsa-mir-155</th>\n",
       "      <td>1.615045</td>\n",
       "      <td>17.284765</td>\n",
       "      <td>35.0</td>\n",
       "      <td>56.526573</td>\n",
       "      <td>604.966797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hsa-mir-17</th>\n",
       "      <td>0.882531</td>\n",
       "      <td>8.431946</td>\n",
       "      <td>28.0</td>\n",
       "      <td>24.710873</td>\n",
       "      <td>236.094482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hsa-mir-181b-2</th>\n",
       "      <td>0.401898</td>\n",
       "      <td>7.353311</td>\n",
       "      <td>21.0</td>\n",
       "      <td>8.439868</td>\n",
       "      <td>154.419525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hsa-mir-186</th>\n",
       "      <td>0.133454</td>\n",
       "      <td>3.656089</td>\n",
       "      <td>22.0</td>\n",
       "      <td>2.935984</td>\n",
       "      <td>80.433952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hsa-mir-188</th>\n",
       "      <td>0.341396</td>\n",
       "      <td>11.833348</td>\n",
       "      <td>43.0</td>\n",
       "      <td>14.680015</td>\n",
       "      <td>508.833984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hsa-mir-18a</th>\n",
       "      <td>0.324786</td>\n",
       "      <td>9.655540</td>\n",
       "      <td>36.0</td>\n",
       "      <td>11.692282</td>\n",
       "      <td>347.599426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hsa-mir-193a</th>\n",
       "      <td>0.301710</td>\n",
       "      <td>7.766084</td>\n",
       "      <td>40.0</td>\n",
       "      <td>12.068409</td>\n",
       "      <td>310.643341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hsa-mir-194-2</th>\n",
       "      <td>0.356977</td>\n",
       "      <td>9.429112</td>\n",
       "      <td>74.0</td>\n",
       "      <td>26.416302</td>\n",
       "      <td>697.754333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hsa-mir-199a-2</th>\n",
       "      <td>1.788141</td>\n",
       "      <td>20.247747</td>\n",
       "      <td>63.0</td>\n",
       "      <td>112.652885</td>\n",
       "      <td>1275.608032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hsa-mir-19a</th>\n",
       "      <td>0.267343</td>\n",
       "      <td>5.179376</td>\n",
       "      <td>37.0</td>\n",
       "      <td>9.891685</td>\n",
       "      <td>191.636917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hsa-mir-200a</th>\n",
       "      <td>0.522268</td>\n",
       "      <td>9.014202</td>\n",
       "      <td>30.0</td>\n",
       "      <td>15.668044</td>\n",
       "      <td>270.426056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hsa-mir-200b</th>\n",
       "      <td>0.485025</td>\n",
       "      <td>8.125775</td>\n",
       "      <td>74.0</td>\n",
       "      <td>35.891853</td>\n",
       "      <td>601.307373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hsa-mir-20a</th>\n",
       "      <td>0.702215</td>\n",
       "      <td>10.057363</td>\n",
       "      <td>38.0</td>\n",
       "      <td>26.684175</td>\n",
       "      <td>382.179779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hsa-mir-21</th>\n",
       "      <td>0.297323</td>\n",
       "      <td>7.448070</td>\n",
       "      <td>26.0</td>\n",
       "      <td>7.730410</td>\n",
       "      <td>193.649811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hsa-mir-222</th>\n",
       "      <td>0.184344</td>\n",
       "      <td>5.598639</td>\n",
       "      <td>60.0</td>\n",
       "      <td>11.060647</td>\n",
       "      <td>335.918335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hsa-mir-223</th>\n",
       "      <td>0.292524</td>\n",
       "      <td>4.529940</td>\n",
       "      <td>18.0</td>\n",
       "      <td>5.265428</td>\n",
       "      <td>81.538918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hsa-mir-23b</th>\n",
       "      <td>0.305509</td>\n",
       "      <td>7.003876</td>\n",
       "      <td>28.0</td>\n",
       "      <td>8.554250</td>\n",
       "      <td>196.108521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hsa-mir-24-1</th>\n",
       "      <td>0.202710</td>\n",
       "      <td>5.052287</td>\n",
       "      <td>43.0</td>\n",
       "      <td>8.716543</td>\n",
       "      <td>217.248337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hsa-mir-27b</th>\n",
       "      <td>0.186208</td>\n",
       "      <td>4.370798</td>\n",
       "      <td>37.0</td>\n",
       "      <td>6.889702</td>\n",
       "      <td>161.719528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hsa-mir-28</th>\n",
       "      <td>0.550724</td>\n",
       "      <td>20.776741</td>\n",
       "      <td>33.0</td>\n",
       "      <td>18.173893</td>\n",
       "      <td>685.632446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hsa-mir-3200</th>\n",
       "      <td>0.184205</td>\n",
       "      <td>8.712737</td>\n",
       "      <td>60.0</td>\n",
       "      <td>11.052292</td>\n",
       "      <td>522.764221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hsa-mir-3613</th>\n",
       "      <td>0.121476</td>\n",
       "      <td>6.945448</td>\n",
       "      <td>32.0</td>\n",
       "      <td>3.887235</td>\n",
       "      <td>222.254333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hsa-mir-3615</th>\n",
       "      <td>0.234838</td>\n",
       "      <td>6.415769</td>\n",
       "      <td>68.0</td>\n",
       "      <td>15.969017</td>\n",
       "      <td>436.272308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hsa-mir-365-1</th>\n",
       "      <td>0.472695</td>\n",
       "      <td>10.494973</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.836169</td>\n",
       "      <td>62.969837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hsa-mir-365-2</th>\n",
       "      <td>0.123628</td>\n",
       "      <td>4.263630</td>\n",
       "      <td>22.0</td>\n",
       "      <td>2.719826</td>\n",
       "      <td>93.799866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hsa-mir-3651</th>\n",
       "      <td>0.127976</td>\n",
       "      <td>4.143882</td>\n",
       "      <td>82.0</td>\n",
       "      <td>10.494069</td>\n",
       "      <td>339.798309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hsa-mir-3676</th>\n",
       "      <td>0.379377</td>\n",
       "      <td>10.413823</td>\n",
       "      <td>55.0</td>\n",
       "      <td>20.865757</td>\n",
       "      <td>572.760254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hsa-mir-423</th>\n",
       "      <td>0.178853</td>\n",
       "      <td>8.248012</td>\n",
       "      <td>41.0</td>\n",
       "      <td>7.332967</td>\n",
       "      <td>338.168488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hsa-mir-429</th>\n",
       "      <td>0.806703</td>\n",
       "      <td>11.647719</td>\n",
       "      <td>71.0</td>\n",
       "      <td>57.275898</td>\n",
       "      <td>826.988098</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    gain      cover  weight  total_gain  total_cover\n",
       "hsa-let-7i      1.040161  16.614639    59.0   61.369476   980.263733\n",
       "hsa-mir-1-2     0.174002   5.095908    20.0    3.480048   101.918167\n",
       "hsa-mir-10a     0.258901   5.837817    58.0   15.016255   338.593384\n",
       "hsa-mir-10b     0.217785   5.103403    18.0    3.920134    91.861244\n",
       "hsa-mir-1228    0.239293   5.473589    45.0   10.768188   246.311508\n",
       "hsa-mir-125a    0.212783   5.898917    38.0    8.085759   224.158829\n",
       "hsa-mir-125b-1  0.221412   5.084087    53.0   11.734852   269.456604\n",
       "hsa-mir-1277    0.166627   4.382925    31.0    5.165445   135.870667\n",
       "hsa-mir-129-1   0.833234   7.673101    64.0   53.326962   491.078491\n",
       "hsa-mir-1307    0.140200   5.436034    58.0    8.131577   315.289978\n",
       "hsa-mir-130b    0.286619   7.942135    33.0    9.458432   262.090454\n",
       "hsa-mir-133a-1  0.222085   4.599783    53.0   11.770526   243.788498\n",
       "hsa-mir-133a-2  0.275118   9.722225    58.0   15.956835   563.889038\n",
       "hsa-mir-133b    0.061800   4.632619    39.0    2.410219   180.672134\n",
       "hsa-mir-135a-2  0.122232   4.478873    57.0    6.967252   255.295761\n",
       "hsa-mir-139     0.330916   6.503644    37.0   12.243883   240.634827\n",
       "hsa-mir-142     0.197411   6.304322    30.0    5.922344   189.129669\n",
       "hsa-mir-153-2   0.186509   4.583476    25.0    4.662715   114.586906\n",
       "hsa-mir-155     1.615045  17.284765    35.0   56.526573   604.966797\n",
       "hsa-mir-17      0.882531   8.431946    28.0   24.710873   236.094482\n",
       "hsa-mir-181b-2  0.401898   7.353311    21.0    8.439868   154.419525\n",
       "hsa-mir-186     0.133454   3.656089    22.0    2.935984    80.433952\n",
       "hsa-mir-188     0.341396  11.833348    43.0   14.680015   508.833984\n",
       "hsa-mir-18a     0.324786   9.655540    36.0   11.692282   347.599426\n",
       "hsa-mir-193a    0.301710   7.766084    40.0   12.068409   310.643341\n",
       "hsa-mir-194-2   0.356977   9.429112    74.0   26.416302   697.754333\n",
       "hsa-mir-199a-2  1.788141  20.247747    63.0  112.652885  1275.608032\n",
       "hsa-mir-19a     0.267343   5.179376    37.0    9.891685   191.636917\n",
       "hsa-mir-200a    0.522268   9.014202    30.0   15.668044   270.426056\n",
       "hsa-mir-200b    0.485025   8.125775    74.0   35.891853   601.307373\n",
       "hsa-mir-20a     0.702215  10.057363    38.0   26.684175   382.179779\n",
       "hsa-mir-21      0.297323   7.448070    26.0    7.730410   193.649811\n",
       "hsa-mir-222     0.184344   5.598639    60.0   11.060647   335.918335\n",
       "hsa-mir-223     0.292524   4.529940    18.0    5.265428    81.538918\n",
       "hsa-mir-23b     0.305509   7.003876    28.0    8.554250   196.108521\n",
       "hsa-mir-24-1    0.202710   5.052287    43.0    8.716543   217.248337\n",
       "hsa-mir-27b     0.186208   4.370798    37.0    6.889702   161.719528\n",
       "hsa-mir-28      0.550724  20.776741    33.0   18.173893   685.632446\n",
       "hsa-mir-3200    0.184205   8.712737    60.0   11.052292   522.764221\n",
       "hsa-mir-3613    0.121476   6.945448    32.0    3.887235   222.254333\n",
       "hsa-mir-3615    0.234838   6.415769    68.0   15.969017   436.272308\n",
       "hsa-mir-365-1   0.472695  10.494973     6.0    2.836169    62.969837\n",
       "hsa-mir-365-2   0.123628   4.263630    22.0    2.719826    93.799866\n",
       "hsa-mir-3651    0.127976   4.143882    82.0   10.494069   339.798309\n",
       "hsa-mir-3676    0.379377  10.413823    55.0   20.865757   572.760254\n",
       "hsa-mir-423     0.178853   8.248012    41.0    7.332967   338.168488\n",
       "hsa-mir-429     0.806703  11.647719    71.0   57.275898   826.988098"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c60f90f0",
   "metadata": {},
   "source": [
    "# Autogluon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4b1b2c40",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# !pip install autogluon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "d4afdc70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install mxnet --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5cd55c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from autogluon.tabular import TabularPredictor as task\n",
    "from sklearn.model_selection import train_test_split\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c02c6588",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_df_final = pd.concat([input_df,input_df_val])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1c429890",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"../final_results/AutoGluon/models/microRNA\"\n",
      "Beginning AutoGluon training ... Time limit = 360s\n",
      "AutoGluon will save models to \"../final_results/AutoGluon/models/microRNA/\"\n",
      "AutoGluon Version:  0.3.1\n",
      "Train Data Rows:    219\n",
      "Train Data Columns: 47\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'multiclass' (because dtype of label-column == int, but few unique label-values observed).\n",
      "\t3 unique label values:  [1, 0, 2]\n",
      "\tIf 'multiclass' is not the correct problem_type, please manually specify the problem_type argument in fit() (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Train Data Class Count: 3\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    126128.11 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.08 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 47 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 47 | ['hsa-let-7i', 'hsa-mir-1-2', 'hsa-mir-10a', 'hsa-mir-10b', 'hsa-mir-1228', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('int', ['bool']) : 47 | ['hsa-let-7i', 'hsa-mir-1-2', 'hsa-mir-10a', 'hsa-mir-10b', 'hsa-mir-1228', ...]\n",
      "\t0.1s = Fit runtime\n",
      "\t47 features in original data used to generate 47 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.01 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.09s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'roc_auc_ovo_macro'\n",
      "\tThis metric expects predicted probabilities rather than predicted class labels, so you'll need to use predict_proba() instead of predict()\n",
      "\tTo change this, specify the eval_metric argument of fit()\n",
      "Automatically generating train/validation split with holdout_frac=0.2, Train Rows: 175, Val Rows: 44\n",
      "Fitting 13 L1 models ...\n",
      "Fitting model: KNeighborsUnif ... Training model for up to 359.91s of the 359.91s of remaining time.\n",
      "\tNo valid features to train KNeighborsUnif... Skipping this model.\n",
      "Fitting model: KNeighborsDist ... Training model for up to 359.91s of the 359.91s of remaining time.\n",
      "\tNo valid features to train KNeighborsDist... Skipping this model.\n",
      "Fitting model: NeuralNetFastAI ... Training model for up to 359.91s of the 359.91s of remaining time.\n",
      "\tWarning: Exception caused NeuralNetFastAI to fail during training... Skipping this model.\n",
      "\t\tfuture feature annotations is not defined (dispatch.py, line 4)\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/autogluon/tabular/trainer/abstract_trainer.py\", line 962, in _train_and_save\n",
      "    model = self._train_single(X, y, model, X_val, y_val, **model_fit_kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/autogluon/tabular/trainer/abstract_trainer.py\", line 934, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, **model_fit_kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 522, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/autogluon/tabular/models/fastainn/tabular_nn_fastai.py\", line 163, in _fit\n",
      "    try_import_fastai()\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/autogluon/core/utils/try_import.py\", line 107, in try_import_fastai\n",
      "    import autogluon.tabular.models.fastainn.imports_helper\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/autogluon/tabular/models/fastainn/imports_helper.py\", line 1, in <module>\n",
      "    from fastai.tabular.all import *\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/fastai/tabular/all.py\", line 1, in <module>\n",
      "    from ..basics import *\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/fastai/basics.py\", line 1, in <module>\n",
      "    from .data.all import *\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/fastai/data/all.py\", line 1, in <module>\n",
      "    from ..torch_basics import *\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/fastai/torch_basics.py\", line 9, in <module>\n",
      "    from .imports import *\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/fastai/imports.py\", line 30, in <module>\n",
      "    from fastcore.all import *\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/fastcore/all.py\", line 3, in <module>\n",
      "    from .dispatch import *\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/fastcore/dispatch.py\", line 4\n",
      "    from __future__ import annotations\n",
      "                                     ^\n",
      "SyntaxError: future feature annotations is not defined\n",
      "Fitting model: LightGBMXT ... Training model for up to 359.9s of the 359.89s of remaining time.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\t0.9156\t = Validation score   (roc_auc_ovo_macro)\n",
      "\t3.06s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBM ... Training model for up to 356.83s of the 356.82s of remaining time.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\t0.9156\t = Validation score   (roc_auc_ovo_macro)\n",
      "\t3.13s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: RandomForestGini ... Training model for up to 353.68s of the 353.68s of remaining time.\n",
      "\t0.9142\t = Validation score   (roc_auc_ovo_macro)\n",
      "\t0.63s\t = Training   runtime\n",
      "\t0.11s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr ... Training model for up to 352.94s of the 352.93s of remaining time.\n",
      "\t0.911\t = Validation score   (roc_auc_ovo_macro)\n",
      "\t0.62s\t = Training   runtime\n",
      "\t0.11s\t = Validation runtime\n",
      "Fitting model: CatBoost ... Training model for up to 352.19s of the 352.19s of remaining time.\n",
      "Metric roc_auc_ovo_macro is not supported by this model - using AUC:type=Mu instead\n",
      "\t0.9131\t = Validation score   (roc_auc_ovo_macro)\n",
      "\t0.52s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini ... Training model for up to 351.67s of the 351.67s of remaining time.\n",
      "\t0.8963\t = Validation score   (roc_auc_ovo_macro)\n",
      "\t0.63s\t = Training   runtime\n",
      "\t0.11s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr ... Training model for up to 350.92s of the 350.92s of remaining time.\n",
      "\t0.915\t = Validation score   (roc_auc_ovo_macro)\n",
      "\t0.62s\t = Training   runtime\n",
      "\t0.11s\t = Validation runtime\n",
      "Fitting model: XGBoost ... Training model for up to 350.18s of the 350.17s of remaining time.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:05:42] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t0.9112\t = Validation score   (roc_auc_ovo_macro)\n",
      "\t2.17s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: NeuralNetMXNet ... Training model for up to 347.93s of the 347.93s of remaining time.\n",
      "\t0.9009\t = Validation score   (roc_auc_ovo_macro)\n",
      "\t3.06s\t = Training   runtime\n",
      "\t0.14s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge ... Training model for up to 344.72s of the 344.72s of remaining time.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\t0.8849\t = Validation score   (roc_auc_ovo_macro)\n",
      "\t11.24s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 359.91s of the 332.75s of remaining time.\n",
      "\t0.9249\t = Validation score   (roc_auc_ovo_macro)\n",
      "\t2.86s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 30.13s ...\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"../final_results/AutoGluon/models/microRNA/\")\n"
     ]
    }
   ],
   "source": [
    "time_limit = 180*2\n",
    "metric = 'roc_auc_ovo_macro' \n",
    "save_path = '../final_results/AutoGluon/models/microRNA'  # specifies folder to store trained models\n",
    "predictor = task(\n",
    "    label=label, \n",
    "    path=save_path, \n",
    "    eval_metric=metric).fit(input_df_final, time_limit=time_limit)#,                           \n",
    "#         hyperparameters=hyperparameters, hyperparameter_tune_kwargs=hyperparameter_tune_kwargs,)#, presets='best_quality')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "eabb32fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluation: roc_auc_ovo_macro on test data: 0.8744520030234316\n",
      "Evaluations on test data:\n",
      "{\n",
      "    \"roc_auc_ovo_macro\": 0.8744520030234316,\n",
      "    \"accuracy\": 0.7021276595744681,\n",
      "    \"balanced_accuracy\": 0.7031746031746032,\n",
      "    \"mcc\": 0.5228531454003328\n",
      "}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'roc_auc_ovo_macro': 0.8744520030234316,\n",
       " 'accuracy': 0.7021276595744681,\n",
       " 'balanced_accuracy': 0.7031746031746032,\n",
       " 'mcc': 0.5228531454003328}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.evaluate(input_df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ab285775",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>score_val</th>\n",
       "      <th>pred_time_val</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>pred_time_val_marginal</th>\n",
       "      <th>fit_time_marginal</th>\n",
       "      <th>stack_level</th>\n",
       "      <th>can_infer</th>\n",
       "      <th>fit_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WeightedEnsemble_L2</td>\n",
       "      <td>0.924908</td>\n",
       "      <td>0.343500</td>\n",
       "      <td>13.613422</td>\n",
       "      <td>0.003109</td>\n",
       "      <td>2.861128</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LightGBM</td>\n",
       "      <td>0.915629</td>\n",
       "      <td>0.005049</td>\n",
       "      <td>3.131966</td>\n",
       "      <td>0.005049</td>\n",
       "      <td>3.131966</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LightGBMXT</td>\n",
       "      <td>0.915629</td>\n",
       "      <td>0.005092</td>\n",
       "      <td>3.059973</td>\n",
       "      <td>0.005092</td>\n",
       "      <td>3.059973</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ExtraTreesEntr</td>\n",
       "      <td>0.914957</td>\n",
       "      <td>0.105868</td>\n",
       "      <td>0.623858</td>\n",
       "      <td>0.105868</td>\n",
       "      <td>0.623858</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RandomForestGini</td>\n",
       "      <td>0.914225</td>\n",
       "      <td>0.105871</td>\n",
       "      <td>0.625833</td>\n",
       "      <td>0.105871</td>\n",
       "      <td>0.625833</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>CatBoost</td>\n",
       "      <td>0.913065</td>\n",
       "      <td>0.004955</td>\n",
       "      <td>0.515225</td>\n",
       "      <td>0.004955</td>\n",
       "      <td>0.515225</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.911172</td>\n",
       "      <td>0.007715</td>\n",
       "      <td>2.172333</td>\n",
       "      <td>0.007715</td>\n",
       "      <td>2.172333</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>RandomForestEntr</td>\n",
       "      <td>0.910989</td>\n",
       "      <td>0.105841</td>\n",
       "      <td>0.623105</td>\n",
       "      <td>0.105841</td>\n",
       "      <td>0.623105</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NeuralNetMXNet</td>\n",
       "      <td>0.900916</td>\n",
       "      <td>0.144591</td>\n",
       "      <td>3.062260</td>\n",
       "      <td>0.144591</td>\n",
       "      <td>3.062260</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ExtraTreesGini</td>\n",
       "      <td>0.896337</td>\n",
       "      <td>0.105860</td>\n",
       "      <td>0.626754</td>\n",
       "      <td>0.105860</td>\n",
       "      <td>0.626754</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>LightGBMLarge</td>\n",
       "      <td>0.884921</td>\n",
       "      <td>0.005209</td>\n",
       "      <td>11.239410</td>\n",
       "      <td>0.005209</td>\n",
       "      <td>11.239410</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  model  score_val  pred_time_val   fit_time  \\\n",
       "0   WeightedEnsemble_L2   0.924908       0.343500  13.613422   \n",
       "1              LightGBM   0.915629       0.005049   3.131966   \n",
       "2            LightGBMXT   0.915629       0.005092   3.059973   \n",
       "3        ExtraTreesEntr   0.914957       0.105868   0.623858   \n",
       "4      RandomForestGini   0.914225       0.105871   0.625833   \n",
       "5              CatBoost   0.913065       0.004955   0.515225   \n",
       "6               XGBoost   0.911172       0.007715   2.172333   \n",
       "7      RandomForestEntr   0.910989       0.105841   0.623105   \n",
       "8        NeuralNetMXNet   0.900916       0.144591   3.062260   \n",
       "9        ExtraTreesGini   0.896337       0.105860   0.626754   \n",
       "10        LightGBMLarge   0.884921       0.005209  11.239410   \n",
       "\n",
       "    pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  \\\n",
       "0                 0.003109           2.861128            2       True   \n",
       "1                 0.005049           3.131966            1       True   \n",
       "2                 0.005092           3.059973            1       True   \n",
       "3                 0.105868           0.623858            1       True   \n",
       "4                 0.105871           0.625833            1       True   \n",
       "5                 0.004955           0.515225            1       True   \n",
       "6                 0.007715           2.172333            1       True   \n",
       "7                 0.105841           0.623105            1       True   \n",
       "8                 0.144591           3.062260            1       True   \n",
       "9                 0.105860           0.626754            1       True   \n",
       "10                0.005209          11.239410            1       True   \n",
       "\n",
       "    fit_order  \n",
       "0          11  \n",
       "1           2  \n",
       "2           1  \n",
       "3           7  \n",
       "4           3  \n",
       "5           5  \n",
       "6           8  \n",
       "7           4  \n",
       "8           9  \n",
       "9           6  \n",
       "10         10  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.leaderboard(silent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "efb24123",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictor.leaderboard(input_df_test, silent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f45a0a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pred_probs = predictor.predict_proba(test_data_nolab)\n",
    "# print(\"Predictions:  \\n\", y_pred)\n",
    "# autogluon_performance = predictor.evaluate_predictions(y_true=y_test, y_pred=pred_probs, auxiliary_metrics=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "17582eb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing feature importance via permutation shuffling for 47 features using 94 rows with 3 shuffle sets...\n",
      "\t65.82s\t= Expected runtime (21.94s per shuffle set)\n",
      "\t2.38s\t= Actual runtime (Completed 3 of 3 shuffle sets)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.76 s, sys: 332 ms, total: 4.09 s\n",
      "Wall time: 2.41 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>importance</th>\n",
       "      <th>stddev</th>\n",
       "      <th>p_value</th>\n",
       "      <th>n</th>\n",
       "      <th>p99_high</th>\n",
       "      <th>p99_low</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>hsa-mir-199a-2</th>\n",
       "      <td>0.019959</td>\n",
       "      <td>0.003170</td>\n",
       "      <td>0.004152</td>\n",
       "      <td>3</td>\n",
       "      <td>0.038124</td>\n",
       "      <td>0.001794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hsa-mir-129-1</th>\n",
       "      <td>0.014781</td>\n",
       "      <td>0.005329</td>\n",
       "      <td>0.020353</td>\n",
       "      <td>3</td>\n",
       "      <td>0.045320</td>\n",
       "      <td>-0.015757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hsa-mir-23b</th>\n",
       "      <td>0.011949</td>\n",
       "      <td>0.004634</td>\n",
       "      <td>0.023329</td>\n",
       "      <td>3</td>\n",
       "      <td>0.038504</td>\n",
       "      <td>-0.014606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hsa-mir-200b</th>\n",
       "      <td>0.010464</td>\n",
       "      <td>0.005660</td>\n",
       "      <td>0.042622</td>\n",
       "      <td>3</td>\n",
       "      <td>0.042899</td>\n",
       "      <td>-0.021970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hsa-let-7i</th>\n",
       "      <td>0.008749</td>\n",
       "      <td>0.008673</td>\n",
       "      <td>0.111355</td>\n",
       "      <td>3</td>\n",
       "      <td>0.058447</td>\n",
       "      <td>-0.040949</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                importance    stddev   p_value  n  p99_high   p99_low\n",
       "hsa-mir-199a-2    0.019959  0.003170  0.004152  3  0.038124  0.001794\n",
       "hsa-mir-129-1     0.014781  0.005329  0.020353  3  0.045320 -0.015757\n",
       "hsa-mir-23b       0.011949  0.004634  0.023329  3  0.038504 -0.014606\n",
       "hsa-mir-200b      0.010464  0.005660  0.042622  3  0.042899 -0.021970\n",
       "hsa-let-7i        0.008749  0.008673  0.111355  3  0.058447 -0.040949"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "## Feature importance by autogluon\n",
    "\n",
    "ag_feature_importance = predictor.feature_importance(input_df_test)\n",
    "ag_feature_importance.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "3d77cc90",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing feature importance via permutation shuffling for 47 features using 219 rows with 3 shuffle sets...\n",
      "\t65.89s\t= Expected runtime (21.96s per shuffle set)\n",
      "\t2.52s\t= Actual runtime (Completed 3 of 3 shuffle sets)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.85 s, sys: 280 ms, total: 6.13 s\n",
      "Wall time: 2.54 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>importance</th>\n",
       "      <th>stddev</th>\n",
       "      <th>p_value</th>\n",
       "      <th>n</th>\n",
       "      <th>p99_high</th>\n",
       "      <th>p99_low</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>hsa-mir-199a-2</th>\n",
       "      <td>0.004600</td>\n",
       "      <td>0.000780</td>\n",
       "      <td>0.004726</td>\n",
       "      <td>3</td>\n",
       "      <td>0.009071</td>\n",
       "      <td>0.000130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hsa-mir-200b</th>\n",
       "      <td>0.003270</td>\n",
       "      <td>0.001210</td>\n",
       "      <td>0.021385</td>\n",
       "      <td>3</td>\n",
       "      <td>0.010205</td>\n",
       "      <td>-0.003666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hsa-mir-188</th>\n",
       "      <td>0.002466</td>\n",
       "      <td>0.000602</td>\n",
       "      <td>0.009648</td>\n",
       "      <td>3</td>\n",
       "      <td>0.005915</td>\n",
       "      <td>-0.000984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hsa-let-7i</th>\n",
       "      <td>0.002301</td>\n",
       "      <td>0.000293</td>\n",
       "      <td>0.002682</td>\n",
       "      <td>3</td>\n",
       "      <td>0.003981</td>\n",
       "      <td>0.000622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hsa-mir-129-1</th>\n",
       "      <td>0.002059</td>\n",
       "      <td>0.000912</td>\n",
       "      <td>0.029808</td>\n",
       "      <td>3</td>\n",
       "      <td>0.007285</td>\n",
       "      <td>-0.003167</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                importance    stddev   p_value  n  p99_high   p99_low\n",
       "hsa-mir-199a-2    0.004600  0.000780  0.004726  3  0.009071  0.000130\n",
       "hsa-mir-200b      0.003270  0.001210  0.021385  3  0.010205 -0.003666\n",
       "hsa-mir-188       0.002466  0.000602  0.009648  3  0.005915 -0.000984\n",
       "hsa-let-7i        0.002301  0.000293  0.002682  3  0.003981  0.000622\n",
       "hsa-mir-129-1     0.002059  0.000912  0.029808  3  0.007285 -0.003167"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "## Feature importance by autogluon\n",
    "\n",
    "ag_feature_importance = predictor.feature_importance(input_df_test)\n",
    "ag_feature_importance.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "d6faf655",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing feature importance via permutation shuffling for 47 features using 94 rows with 3 shuffle sets...\n",
      "\t66.45s\t= Expected runtime (22.15s per shuffle set)\n",
      "\t2.38s\t= Actual runtime (Completed 3 of 3 shuffle sets)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.85 s, sys: 306 ms, total: 4.16 s\n",
      "Wall time: 2.4 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>importance</th>\n",
       "      <th>stddev</th>\n",
       "      <th>p_value</th>\n",
       "      <th>n</th>\n",
       "      <th>p99_high</th>\n",
       "      <th>p99_low</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>hsa-mir-199a-2</th>\n",
       "      <td>0.019959</td>\n",
       "      <td>0.003170</td>\n",
       "      <td>0.004152</td>\n",
       "      <td>3</td>\n",
       "      <td>0.038124</td>\n",
       "      <td>0.001794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hsa-mir-129-1</th>\n",
       "      <td>0.014781</td>\n",
       "      <td>0.005329</td>\n",
       "      <td>0.020353</td>\n",
       "      <td>3</td>\n",
       "      <td>0.045320</td>\n",
       "      <td>-0.015757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hsa-mir-23b</th>\n",
       "      <td>0.011949</td>\n",
       "      <td>0.004634</td>\n",
       "      <td>0.023329</td>\n",
       "      <td>3</td>\n",
       "      <td>0.038504</td>\n",
       "      <td>-0.014606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hsa-mir-200b</th>\n",
       "      <td>0.010464</td>\n",
       "      <td>0.005660</td>\n",
       "      <td>0.042622</td>\n",
       "      <td>3</td>\n",
       "      <td>0.042899</td>\n",
       "      <td>-0.021970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hsa-let-7i</th>\n",
       "      <td>0.008749</td>\n",
       "      <td>0.008673</td>\n",
       "      <td>0.111355</td>\n",
       "      <td>3</td>\n",
       "      <td>0.058447</td>\n",
       "      <td>-0.040949</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                importance    stddev   p_value  n  p99_high   p99_low\n",
       "hsa-mir-199a-2    0.019959  0.003170  0.004152  3  0.038124  0.001794\n",
       "hsa-mir-129-1     0.014781  0.005329  0.020353  3  0.045320 -0.015757\n",
       "hsa-mir-23b       0.011949  0.004634  0.023329  3  0.038504 -0.014606\n",
       "hsa-mir-200b      0.010464  0.005660  0.042622  3  0.042899 -0.021970\n",
       "hsa-let-7i        0.008749  0.008673  0.111355  3  0.058447 -0.040949"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "## Feature importance by autogluon\n",
    "\n",
    "ag_feature_importance = predictor.feature_importance(input_df_test)\n",
    "ag_feature_importance.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0261c73e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
